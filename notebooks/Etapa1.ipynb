{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf6c17a9",
   "metadata": {},
   "source": [
    "# ETAPA 1: Limpieza y preparación de datos\n",
    "\n",
    "**Objetivo:** Comprender la estructura del dataset y generar una base consolidada y limpia.\n",
    "\n",
    "**Rango temporal:** 1 mes de datos (ejemplo: marzo 2020).\n",
    "\n",
    "**Dificultad:** Básica – operaciones individuales sobre un solo archivo CSV.\n",
    "\n",
    "**Ítems solicitados:**\n",
    "1. Cargar y visualizar los primeros 5 registros del archivo 01-22-2020.csv.\n",
    "2. Mostrar el número total de filas y columnas del DataFrame.\n",
    "3. Describir los tipos de datos (dtypes) y convertir las columnas necesarias (por ejemplo,\n",
    "fechas).\n",
    "4. Detectar y mostrar valores nulos o faltantes por columna.\n",
    "5. Eliminar columnas irrelevantes (por ejemplo, códigos FIPS o coordenadas si no se usarán).\n",
    "6. Estandarizar nombres de columnas (usar formato snake_case).\n",
    "7. Homogeneizar nombres de países (ej. “US” → “United States”).\n",
    "8. Convertir la columna Last_Update al formato YYYY-MM-DD.\n",
    "9. Crear una columna active_cases = Confirmed - Deaths - Recovered.\n",
    "10. Guardar el DataFrame limpio como covid_clean_enero2020.csv e indicar su tamaño en MB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c1b863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuración centralizada importada\n"
     ]
    }
   ],
   "source": [
    "# Importar configuración centralizada\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Agregar el directorio src al path para importar config\n",
    "sys.path.insert(0, os.path.join('..', 'src'))\n",
    "from config import COUNTRY_MAPPING, COLUMNS_TO_DROP, NUMERIC_COLUMNS, load_daily_reports, clean_covid_data\n",
    "\n",
    "print(\"✓ Configuración centralizada importada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8f5e70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 03-01-2020.csv\n",
      "✓ 03-02-2020.csv\n",
      "✓ 03-03-2020.csv\n",
      "✓ 03-04-2020.csv\n",
      "✓ 03-05-2020.csv\n",
      "✓ 03-06-2020.csv\n",
      "✓ 03-07-2020.csv\n",
      "✓ 03-08-2020.csv\n",
      "✓ 03-09-2020.csv\n",
      "✓ 03-10-2020.csv\n",
      "✓ 03-11-2020.csv\n",
      "✓ 03-12-2020.csv\n",
      "✓ 03-13-2020.csv\n",
      "✓ 03-14-2020.csv\n",
      "✓ 03-15-2020.csv\n",
      "✓ 03-16-2020.csv\n",
      "✓ 03-17-2020.csv\n",
      "✓ 03-18-2020.csv\n",
      "✓ 03-19-2020.csv\n",
      "✓ 03-20-2020.csv\n",
      "✓ 03-21-2020.csv\n",
      "✓ 03-22-2020.csv\n",
      "✓ 03-23-2020.csv\n",
      "✓ 03-24-2020.csv\n",
      "✓ 03-25-2020.csv\n",
      "✓ 03-26-2020.csv\n",
      "✓ 03-27-2020.csv\n",
      "✓ 03-28-2020.csv\n",
      "✓ 03-29-2020.csv\n",
      "✓ 03-30-2020.csv\n",
      "✓ 03-31-2020.csv\n",
      "\n",
      "============================================================\n",
      "✓ Cargados 31 archivos diarios\n",
      "✓ Total de registros: 39,198\n",
      "✓ Período: 2020-03-01 → 2020-03-31\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Configuración: ruta a los archivos daily_reports locales\n",
    "# Nota: el notebook está en notebooks/, por eso usamos '../' para subir un nivel\n",
    "DATA_DIR = os.path.join('..', 'data', 'raw', 'COVID-19', 'csse_covid_19_data', 'csse_covid_19_daily_reports')\n",
    "\n",
    "# Rango de fechas a cargar (marzo 2020, día por día)\n",
    "dates = pd.date_range(start='2020-03-01', end='2020-03-31', freq='D')\n",
    "\n",
    "# Lista temporal para acumular los DataFrames de cada día\n",
    "daily_dataframes = []\n",
    "\n",
    "# Leer cada archivo CSV diario y agregarlo a la lista\n",
    "for date in dates:\n",
    "    filename = date.strftime('%m-%d-%Y') + '.csv'  # Formato: MM-DD-YYYY\n",
    "    filepath = os.path.join(DATA_DIR, filename)\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"⚠ Archivo no encontrado: {filename}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        df_day = pd.read_csv(filepath)\n",
    "        df_day['Date'] = date  # Agregar columna con la fecha del archivo\n",
    "        daily_dataframes.append(df_day)\n",
    "        print(f\"✓ {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error en {filename}: {e}\")\n",
    "\n",
    "# Concatenar (apilar verticalmente) todos los DataFrames diarios en uno solo\n",
    "if daily_dataframes:\n",
    "    df_marzo = pd.concat(daily_dataframes, ignore_index=True, sort=False)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"✓ Cargados {len(daily_dataframes)} archivos diarios\")\n",
    "    print(f\"✓ Total de registros: {len(df_marzo):,}\")\n",
    "    print(f\"✓ Período: {df_marzo['Date'].min().date()} → {df_marzo['Date'].max().date()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "else:\n",
    "    df_marzo = pd.DataFrame()\n",
    "    print(\"\\n⚠ No se cargó ningún archivo.\")\n",
    "    print(\"Ejecuta: ./scripts/fetch_jhu_data.sh clone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0d033bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Date</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Active</th>\n",
       "      <th>Combined_Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hubei</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2020-03-01T10:13:19</td>\n",
       "      <td>66907</td>\n",
       "      <td>2761</td>\n",
       "      <td>31536</td>\n",
       "      <td>30.9756</td>\n",
       "      <td>112.2707</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>2020-03-01T23:43:03</td>\n",
       "      <td>3736</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>128.0000</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2020-03-01T23:23:02</td>\n",
       "      <td>1694</td>\n",
       "      <td>34</td>\n",
       "      <td>83</td>\n",
       "      <td>43.0000</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2020-03-01T14:13:18</td>\n",
       "      <td>1349</td>\n",
       "      <td>7</td>\n",
       "      <td>1016</td>\n",
       "      <td>23.3417</td>\n",
       "      <td>113.4244</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Henan</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2020-03-01T14:13:18</td>\n",
       "      <td>1272</td>\n",
       "      <td>22</td>\n",
       "      <td>1198</td>\n",
       "      <td>33.8820</td>\n",
       "      <td>113.6140</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region          Last Update  Confirmed  Deaths  \\\n",
       "0          Hubei  Mainland China  2020-03-01T10:13:19      66907    2761   \n",
       "1            NaN     South Korea  2020-03-01T23:43:03       3736      17   \n",
       "2            NaN           Italy  2020-03-01T23:23:02       1694      34   \n",
       "3      Guangdong  Mainland China  2020-03-01T14:13:18       1349       7   \n",
       "4          Henan  Mainland China  2020-03-01T14:13:18       1272      22   \n",
       "\n",
       "   Recovered  Latitude  Longitude       Date  FIPS Admin2 Province_State  \\\n",
       "0      31536   30.9756   112.2707 2020-03-01   NaN    NaN            NaN   \n",
       "1         30   36.0000   128.0000 2020-03-01   NaN    NaN            NaN   \n",
       "2         83   43.0000    12.0000 2020-03-01   NaN    NaN            NaN   \n",
       "3       1016   23.3417   113.4244 2020-03-01   NaN    NaN            NaN   \n",
       "4       1198   33.8820   113.6140 2020-03-01   NaN    NaN            NaN   \n",
       "\n",
       "  Country_Region Last_Update  Lat  Long_  Active Combined_Key  \n",
       "0            NaN         NaN  NaN    NaN     NaN          NaN  \n",
       "1            NaN         NaN  NaN    NaN     NaN          NaN  \n",
       "2            NaN         NaN  NaN    NaN     NaN          NaN  \n",
       "3            NaN         NaN  NaN    NaN     NaN          NaN  \n",
       "4            NaN         NaN  NaN    NaN     NaN          NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Cargar y visualizar los primeros 5 registros del archivo\n",
    "df_marzo.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "590e7f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Total de filas: 39,198\n",
      "   Total de columnas: 18\n"
     ]
    }
   ],
   "source": [
    "#2. Mostrar el número total de filas y columnas del DataFrame.\n",
    "print(f\"   Total de filas: {df_marzo.shape[0]:,}\")\n",
    "print(f\"   Total de columnas: {df_marzo.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a5ea799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39198 entries, 0 to 39197\n",
      "Data columns (total 18 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Province/State  2993 non-null   object        \n",
      " 1   Country/Region  5555 non-null   object        \n",
      " 2   Last Update     5555 non-null   object        \n",
      " 3   Confirmed       39198 non-null  int64         \n",
      " 4   Deaths          39198 non-null  int64         \n",
      " 5   Recovered       39198 non-null  int64         \n",
      " 6   Latitude        5492 non-null   float64       \n",
      " 7   Longitude       5492 non-null   float64       \n",
      " 8   Date            39198 non-null  datetime64[ns]\n",
      " 9   FIPS            30506 non-null  float64       \n",
      " 10  Admin2          30712 non-null  object        \n",
      " 11  Province_State  31866 non-null  object        \n",
      " 12  Country_Region  33643 non-null  object        \n",
      " 13  Last_Update     33643 non-null  object        \n",
      " 14  Lat             33598 non-null  float64       \n",
      " 15  Long_           33598 non-null  float64       \n",
      " 16  Active          33643 non-null  float64       \n",
      " 17  Combined_Key    33643 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(6), int64(3), object(8)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# 3. Describir los tipos de datos (dtypes) y convertir las columnas necesarias (por ejemplo,fechas)\n",
    "df_marzo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f84fb417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Province/State            object\n",
       "Country/Region            object\n",
       "Last Update               object\n",
       "Confirmed                  int64\n",
       "Deaths                     int64\n",
       "Recovered                  int64\n",
       "Latitude                 float64\n",
       "Longitude                float64\n",
       "Date              datetime64[ns]\n",
       "FIPS                     float64\n",
       "Admin2                    object\n",
       "Province_State            object\n",
       "Country_Region            object\n",
       "Last_Update       datetime64[ns]\n",
       "Lat                      float64\n",
       "Long_                    float64\n",
       "Active                   float64\n",
       "Combined_Key              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convertir las columnas necesarias (por ejemplo,fechas).\n",
    "if 'Last_Update' in df_marzo.columns:\n",
    "    df_marzo['Last_Update'] = pd.to_datetime(df_marzo['Last_Update'], format='mixed', errors='coerce')\n",
    "elif 'Last Update' in df_marzo.columns:\n",
    "    df_marzo['Last Update'] = pd.to_datetime(df_marzo['Last Update'], format='mixed', errors='coerce')\n",
    "\n",
    "numeric_columns = ['Confirmed', 'Deaths', 'Recovered']\n",
    "for col in numeric_columns:\n",
    "    if col in df_marzo.columns:\n",
    "        df_marzo[col] = pd.to_numeric(df_marzo[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "df_marzo.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bf6ffd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Province/State    36205\n",
       "Country/Region    33643\n",
       "Last Update       33643\n",
       "Confirmed             0\n",
       "Deaths                0\n",
       "Recovered             0\n",
       "Latitude          33706\n",
       "Longitude         33706\n",
       "Date                  0\n",
       "FIPS               8692\n",
       "Admin2             8486\n",
       "Province_State     7332\n",
       "Country_Region     5555\n",
       "Last_Update        5555\n",
       "Lat                5600\n",
       "Long_              5600\n",
       "Active             5555\n",
       "Combined_Key       5555\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. Detectar y mostrar valores nulos o faltantes por columna\n",
    "df_marzo.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05f90366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Province/State', 'Country/Region', 'Last Update', 'Confirmed',\n",
       "       'Deaths', 'Recovered', 'Date', 'Province_State', 'Country_Region',\n",
       "       'Last_Update', 'Active'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. Eliminar columnas irrelevantes por ejemplo, códigos FIPS o coordenadas si no se usarán).\n",
    "columns_to_drop = ['FIPS', 'Admin2', 'Lat', 'Long_', 'Latitude', 'Longitude', 'Combined_Key']\n",
    "df_marzo = df_marzo.drop(columns=[col for col in columns_to_drop if col in df_marzo.columns])\n",
    "df_marzo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "748f61e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['province_state', 'country_region', 'last_update', 'confirmed',\n",
       "       'deaths', 'recovered', 'date', 'province_state', 'country_region',\n",
       "       'last_update', 'active'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6. Estandarizar nombres de columnas (usar formato snake_case)\n",
    "df_marzo.columns = df_marzo.columns.str.lower().str.replace(' ', '_').str.replace('/', '_').str.replace('-', '_')\n",
    "df_marzo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d8d1dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Encontradas columnas duplicadas: ['province_state', 'country_region', 'last_update']\n",
      "  ✓ 'province_state' consolidada\n",
      "  ✓ 'country_region' consolidada\n",
      "  ✓ 'last_update' consolidada\n",
      "\n",
      "✓ Columnas finales: ['confirmed', 'deaths', 'recovered', 'date', 'active', 'province_state', 'country_region', 'last_update']\n",
      "  ✓ 'last_update' consolidada\n",
      "\n",
      "✓ Columnas finales: ['confirmed', 'deaths', 'recovered', 'date', 'active', 'province_state', 'country_region', 'last_update']\n"
     ]
    }
   ],
   "source": [
    "#6.5. Eliminar columnas duplicadas (consolidando valores)\n",
    "# Los archivos de marzo 2020 tienen diferentes esquemas que generan columnas duplicadas\n",
    "duplicated_cols = df_marzo.columns[df_marzo.columns.duplicated()].unique()\n",
    "\n",
    "if len(duplicated_cols) > 0:\n",
    "    print(f\"⚠ Encontradas columnas duplicadas: {duplicated_cols.tolist()}\")\n",
    "    \n",
    "    for col_name in duplicated_cols:\n",
    "        # Obtener todas las columnas con este nombre\n",
    "        matching_cols = [i for i, c in enumerate(df_marzo.columns) if c == col_name]\n",
    "        \n",
    "        # Consolidar: tomar el primer valor no nulo de cada fila\n",
    "        consolidated = df_marzo.iloc[:, matching_cols[0]]\n",
    "        for col_idx in matching_cols[1:]:\n",
    "            consolidated = consolidated.fillna(df_marzo.iloc[:, col_idx])\n",
    "        \n",
    "        # Eliminar todas las columnas duplicadas\n",
    "        df_marzo = df_marzo.drop(df_marzo.columns[matching_cols], axis=1)\n",
    "        \n",
    "        # Agregar la columna consolidada\n",
    "        df_marzo[col_name] = consolidated\n",
    "        print(f\"  ✓ '{col_name}' consolidada\")\n",
    "    \n",
    "    print(f\"\\n✓ Columnas finales: {df_marzo.columns.tolist()}\")\n",
    "else:\n",
    "    print(\"✓ No hay columnas duplicadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab1ac912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Top 10 países:\n",
      "country_region\n",
      "United States     31975\n",
      "China              1038\n",
      "Malaysia            527\n",
      "United Kingdom      367\n",
      "Canada              297\n",
      "Australia           255\n",
      "France              180\n",
      "New Zealand          93\n",
      "Netherlands          73\n",
      "Denmark              65\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#7. Homogeneizar nombres de países  (ej. \"US\" → \"United States\").\n",
    "# Usar el mapeo centralizado de src/config.py\n",
    "country_mapping = COUNTRY_MAPPING\n",
    "\n",
    "# Buscar todas las columnas relacionadas con país\n",
    "country_cols = [col for col in df_marzo.columns if 'country' in col.lower()]\n",
    "\n",
    "if country_cols:\n",
    "    # Si ya existe 'country_region', usarla directamente\n",
    "    if 'country_region' in df_marzo.columns:\n",
    "        country_col = 'country_region'\n",
    "    else:\n",
    "        # Si hay múltiples columnas de país, consolidar en una sola\n",
    "        if len(country_cols) > 1:\n",
    "            print(f\"⚠ Se encontraron {len(country_cols)} columnas de país: {country_cols}\")\n",
    "            # Tomar la primera columna no nula de cada fila\n",
    "            df_marzo['country_region'] = df_marzo[country_cols[0]].fillna('')\n",
    "            for col in country_cols[1:]:\n",
    "                df_marzo['country_region'] = df_marzo['country_region'].where(\n",
    "                    df_marzo['country_region'] != '', \n",
    "                    df_marzo[col].fillna('')\n",
    "                )\n",
    "            # Eliminar las columnas originales duplicadas\n",
    "            df_marzo = df_marzo.drop(columns=country_cols)\n",
    "            print(\"✓ Columnas consolidadas en 'country_region'\")\n",
    "        else:\n",
    "            # Solo hay una columna, renombrarla\n",
    "            df_marzo = df_marzo.rename(columns={country_cols[0]: 'country_region'})\n",
    "        \n",
    "        country_col = 'country_region'\n",
    "    \n",
    "    # Aplicar el mapeo de países\n",
    "    df_marzo[country_col] = df_marzo[country_col].replace(country_mapping)\n",
    "    print(f\"✓ Top 10 países:\")\n",
    "    print(df_marzo[country_col].value_counts().head(10))\n",
    "else:\n",
    "    print(\"⚠ No se encontró columna de país en el DataFrame.\")\n",
    "    print(f\"Columnas disponibles: {df_marzo.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a01855e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  last_update\n",
       "0  2020-03-01\n",
       "1  2020-03-01\n",
       "2  2020-03-01\n",
       "3  2020-03-01\n",
       "4  2020-03-01"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8. Convertir la columna Last_Update al formato YYYY-MM-DD\n",
    "if 'last_update' in df_marzo.columns:\n",
    "    df_marzo['last_update'] = pd.to_datetime(df_marzo['last_update'], format='mixed', errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "df_marzo[['last_update']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff3ae4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>active_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66907</td>\n",
       "      <td>2761</td>\n",
       "      <td>31536</td>\n",
       "      <td>32610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3736</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>3689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1694</td>\n",
       "      <td>34</td>\n",
       "      <td>83</td>\n",
       "      <td>1577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1349</td>\n",
       "      <td>7</td>\n",
       "      <td>1016</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1272</td>\n",
       "      <td>22</td>\n",
       "      <td>1198</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   confirmed  deaths  recovered  active_cases\n",
       "0      66907    2761      31536         32610\n",
       "1       3736      17         30          3689\n",
       "2       1694      34         83          1577\n",
       "3       1349       7       1016           326\n",
       "4       1272      22       1198            52"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9. Crear una columna active_cases = Confirmed - Deaths - Recovered\n",
    "df_marzo['active_cases'] = df_marzo['confirmed'] - df_marzo['deaths'] - df_marzo['recovered']\n",
    "df_marzo[['confirmed', 'deaths', 'recovered', 'active_cases']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c612ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado: ../data/processed/covid_clean_marzo2020.csv\n",
      "Tamaño del archivo: 2.10 MB\n"
     ]
    }
   ],
   "source": [
    "#10. Guardar el DataFrame limpio como covid_clean_enero2020.csv e indicar su tamaño en MB.\n",
    "import os\n",
    "\n",
    "output_path = '../data/processed/covid_clean_marzo2020.csv'\n",
    "df_marzo.to_csv(output_path, index=False)\n",
    "\n",
    "file_size_mb = os.path.getsize(output_path) / (1024 * 1024)\n",
    "print(f\"Archivo guardado: {output_path}\")\n",
    "print(f\"Tamaño del archivo: {file_size_mb:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
